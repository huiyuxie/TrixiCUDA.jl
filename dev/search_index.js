var documenterSearchIndex = {"docs":
[{"location":"aws_gpu_setup/#Tutorial-Setting-Up-Cloud-GPUs-for-Running-CUDA.jl","page":"Tutorial 1","title":"Tutorial - Setting Up Cloud GPUs for Running CUDA.jl","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Welcome to this tutorial! If you're looking to use GPUs in the cloud for running Julia programs with CUDA.jl, you're in the right place. This tutorial aims to help you set up cloud GPU on Amazon Web Service (AWS) to run CUDA.jl.","category":"page"},{"location":"aws_gpu_setup/#Prerequisite","page":"Tutorial 1","title":"Prerequisite","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Before the tutorial begins, you should launch P type EC2 instance(s) on your own in AWS. Here are some links for you to quickly get to know key concepts and successfully launch your instance(s).","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"What is Amazon EC2? https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html\nWhich type of EC2 should I use? https://aws.amazon.com/ec2/instance-types/\nHow to launch Amazon EC2? https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html\nWhat is spot instance? (optional) https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html\nHow to work with spot instance? (optional) https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-requests.html","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"The last two resources are optional if the cost isn't a concern for you, and you can choose to stick with on-demand instance(s). However, please note that in both cases you will need to manually request a quota for P type instances before launching.","category":"page"},{"location":"aws_gpu_setup/#Connect-to-Instance(s)","page":"Tutorial 1","title":"Connect to Instance(s)","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Up to this step, we assume that you have already launched your EC2 instance(s). Now, you can connect to your instance(s) via your local terminal or any IDE with an SSH extension.","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Move your key pair file (.pem) to the .ssh folder:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ mv ~/Downloads/<your-key-pair-name>.pem ~/.ssh/<your-key-pair-name>.pem","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Change the permission of the key pair file:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ chmod 600 ~/.ssh/<your-key-pair-name>.pem","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Copy the public IPv4 DNS of your instance(s) from AWS and then connect to your instance(s) via SSH:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ ssh -i ~/.ssh/<your-key-pair-name>.pem ubuntu@<your-ec2-public-ipv4-dns>","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"When prompted with the question Are you sure you want to continue connecting (yes/no)?, enter yes. At this point, you should be able to successfully connect to your instance(s).","category":"page"},{"location":"aws_gpu_setup/#Configure-Julia-Package","page":"Tutorial 1","title":"Configure Julia Package","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"In this step, we assume that you have already connected to your instance(s) and the commands are being executed in your instance(s)'s terminal.","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"You can find the version of the Julia package you want from https://julialang.org/downloads/. For illustration, we are using Julia version 1.10.0 for Linux on x86 64-bit.","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Copy the address of the Julia package and download it to your instance(s):","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ wget https://julialang-s3.julialang.org/bin/linux/x64/1.10/julia-1.10.0-linux-x86_64.tar.gz","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Extract your downloaded package:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ tar -xvf julia-1.10.0-linux-x86_64.tar.gz","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Create a symbolic link to the Julia:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ sudo ln -s ~/julia-1.10.0/bin/julia /usr/local/bin/julia","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Remove the original Julia package (optional):","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ rm julia-1.10.0-linux-x86_64.tar.gz","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Then you should be able to run julia command successfully in your instance(s)'s root directory.","category":"page"},{"location":"aws_gpu_setup/#Configure-CUDA-Toolkit","page":"Tutorial 1","title":"Configure CUDA Toolkit","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Like the former step, we assume that you have connected to your instance(s) and the commands are being executed in your instance(s)'s terminal.","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Then you can easily download and configure the desired version of the CUDA Toolkit based on your selected platform through a set of commands available at https://developer.nvidia.com/cuda-downloads. After that, you may verify the version of the CUDA Toolkit you installed by running the nvcc --version command.","category":"page"},{"location":"aws_gpu_setup/#Add-CUDA-Toolkit-to-Julia","page":"Tutorial 1","title":"Add CUDA Toolkit to Julia","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"In this step, we are going to add CUDA package to Julia. Again, this is based on the fact that you have already connected to your insrance(s).","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Enter into Julia REPL:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ julia","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Enter Jualia package mode and add CUDA to Julia:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"pkg> add CUDA","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Then you can simply test CUDA in Julia by creating a test.jl file like below:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"# This is a test.jl file\nusing CUDA\nCUDA.versioninfo()","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"If the test result displays the version of CUDA without any errors, you have successfully added CUDA to Julia.","category":"page"},{"location":"aws_gpu_setup/#Enable-SSH-with-Git-Repository-(Optional)","page":"Tutorial 1","title":"Enable SSH with Git Repository (Optional)","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"This step is optional but recommended for those who are going to operate their git repository on EC2 instance(s).","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Create an SSH key in your local terminal:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ ssh-keygen -t rsa -b 4096 -C <your-email-address>","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Save the key to the default directory ~/.ssh and enter a passphrase of your choice.","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Change the permission of your SSH key:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ chmod 600 ~/.ssh/id_rsa","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Add your SSH private key to the ssh-agent:","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ ssh-add -k ~/.ssh/id_rsa","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Copy the public key and use it to create a new SSH key in your GitHub.","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Copy the public key into your EC2 instance(s):","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ cat ~/.ssh/id_rsa.pub | ssh -i ~/.ssh/<your-key-pair-name>.pem ubuntu@<your-ec2-public-ipv4-dns> \"cat >> .ssh/authorized_keys\"","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Copy the private key to your EC2 instance(s):","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"$ scp -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -i ~/.ssh/<your-key-pair-name>.pem ~/.ssh/id_rsa ubuntu@<your-ec2-public-ipv4-dns>:~/.ssh/","category":"page"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"Then you can directly git clone and git push (or other operations) in your EC2 instance(s).","category":"page"},{"location":"aws_gpu_setup/#In-The-End","page":"Tutorial 1","title":"In The End","text":"","category":"section"},{"location":"aws_gpu_setup/","page":"Tutorial 1","title":"Tutorial 1","text":"After going through the previous steps, you can use CUDA.jl on your cloud GPU through AWS. Please remember to terminate your instance(s) when you no longer need them, as they will continue to incur charges.","category":"page"},{"location":"dev_env_info/#Development-Environment-Information","page":"Development Environment Information","title":"Development Environment Information","text":"","category":"section"},{"location":"dev_env_info/#Recent-Update","page":"Development Environment Information","title":"Recent Update","text":"","category":"section"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The hardware has been updated for this project recently. The new NVIDIA GeForce Series has been launched to continue implementation and testing of this project. Here is the detailed environment information for this project now.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The following shows the specific CPU information.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"huiyu@huiyuxps15:~$ lscpu\nArchitecture:            x86_64\n  CPU op-mode(s):        32-bit, 64-bit\n  Address sizes:         46 bits physical, 48 bits virtual\n  Byte Order:            Little Endian\nCPU(s):                  20\n  On-line CPU(s) list:   0-19\nVendor ID:               GenuineIntel\n  Model name:            13th Gen Intel(R) Core(TM) i9-13900H\n    CPU family:          6\n    Model:               186\n    Thread(s) per core:  2\n    Core(s) per socket:  10\n    Socket(s):           1\n    Stepping:            2\n    BogoMIPS:            5990.39\n    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse ss\n                         e2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop\n                         _tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_time\n                         r aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb stibp ibrs_enha\n                         nced tpr_shadow vnmi ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid rdsee\n                         d adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves avx_vnni umip waitpkg gfni vae\n                         s vpclmulqdq rdpid movdiri movdir64b fsrm md_clear serialize flush_l1d arch_capabilities\nVirtualization features:\n  Virtualization:        VT-x\n  Hypervisor vendor:     Microsoft\n  Virtualization type:   full\nCaches (sum of all):\n  L1d:                   480 KiB (10 instances)\n  L1i:                   320 KiB (10 instances)\n  L2:                    12.5 MiB (10 instances)\n  L3:                    24 MiB (1 instance)\nVulnerabilities:\n  Gather data sampling:  Not affected\n  Itlb multihit:         Not affected\n  L1tf:                  Not affected\n  Mds:                   Not affected\n  Meltdown:              Not affected\n  Mmio stale data:       Not affected\n  Retbleed:              Mitigation; Enhanced IBRS\n  Spec rstack overflow:  Not affected\n  Spec store bypass:     Mitigation; Speculative Store Bypass disabled via prctl and seccomp\n  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n  Spectre v2:            Mitigation; Enhanced IBRS, IBPB conditional, RSB filling, PBRSB-eIBRS SW sequence\n  Srbds:                 Not affected\n  Tsx async abort:       Not affected","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The following shows the specific GPU information.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"huiyu@huiyuxps15:~$ nvidia-smi\nThu May 16 17:26:16 2024\n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 545.23.07              Driver Version: 546.12       CUDA Version: 12.3     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 4060 ...    On  | 00000000:01:00.0 Off |                  N/A |\n| N/A   43C    P3              11W /  45W |      0MiB /  8188MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n\n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+","category":"page"},{"location":"dev_env_info/#Legacy-(AWS)","page":"Development Environment Information","title":"Legacy (AWS)","text":"","category":"section"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"This project were implemented and tested on AWS EC2 instances. So far, types of EC2 instances used in this project include: p3.2xlarge (single-GPU) and g4dn.12xlarge (multi-GPU). For more information about the EC2 instances, please refer to AWS EC2 Instance Types.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The following information is about the environment of the EC2 instances used in this project.","category":"page"},{"location":"dev_env_info/#AWS-p3.2xlarge","page":"Development Environment Information","title":"AWS p3.2xlarge","text":"","category":"section"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The following shows the specific CPU information of the p3.2xlarge instance used in this project.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"ubuntu@ip-172-31-7-163:~/trixi_cuda$ lscpu\nArchitecture:            x86_64\n  CPU op-mode(s):        32-bit, 64-bit\n  Address sizes:         46 bits physical, 48 bits virtual\n  Byte Order:            Little Endian\nCPU(s):                  8\n  On-line CPU(s) list:   0-7\nVendor ID:               GenuineIntel\n  Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n    CPU family:          6\n    Model:               79\n    Thread(s) per core:  2\n    Core(s) per socket:  4\n    Socket(s):           1\n    Stepping:            1\n    CPU max MHz:         3000.0000\n    CPU min MHz:         1200.0000\n    BogoMIPS:            4600.04\n    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscal\n                         l nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_freq pni\n                          pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdra\n                         nd hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erm\n                         s invpcid rtm rdseed adx xsaveopt\nVirtualization features: \n  Hypervisor vendor:     Xen\n  Virtualization type:   full\nCaches (sum of all):     \n  L1d:                   128 KiB (4 instances)\n  L1i:                   128 KiB (4 instances)\n  L2:                    1 MiB (4 instances)\n  L3:                    45 MiB (1 instance)\nNUMA:                    \n  NUMA node(s):          1\n  NUMA node0 CPU(s):     0-7\nVulnerabilities:         \n  Itlb multihit:         KVM: Mitigation: VMX unsupported\n  L1tf:                  Mitigation; PTE Inversion\n  Mds:                   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\n  Meltdown:              Mitigation; PTI\n  Mmio stale data:       Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\n  Retbleed:              Not affected\n  Spec store bypass:     Vulnerable\n  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n  Spectre v2:            Mitigation; Retpolines, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected\n  Srbds:                 Not affected\n  Tsx async abort:       Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The following shows the specific GPU information of the p3.2xlarge instance used in this project.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"ubuntu@ip-172-31-7-163:~/trixi_cuda$ nvidia-smi\nSat Aug 26 00:38:06 2023       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla V100-SXM2-16GB            On | 00000000:00:1E.0 Off |                    0 |\n| N/A   47C    P0               25W / 300W|      0MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+","category":"page"},{"location":"dev_env_info/#AWS-g4dn.12xlarge","page":"Development Environment Information","title":"AWS g4dn.12xlarge","text":"","category":"section"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The following shows the specific CPU information of the g4dn.12xlarge instance used in this project.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"ubuntu@ip-172-31-4-230:~/trixi_cuda$ lscpu\nArchitecture:            x86_64\n  CPU op-mode(s):        32-bit, 64-bit\n  Address sizes:         46 bits physical, 48 bits virtual\n  Byte Order:            Little Endian\nCPU(s):                  48\n  On-line CPU(s) list:   0-47\nVendor ID:               GenuineIntel\n  Model name:            Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n    CPU family:          6\n    Model:               85\n    Thread(s) per core:  2\n    Core(s) per socket:  24\n    Socket(s):           1\n    Stepping:            7\n    BogoMIPS:            4999.99\n    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clf\n                         lush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch\n                         _perfmon rep_good nopl xtopology nonstop_tsc cpuid aperfmperf tsc_known_fre\n                         q pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popc\n                         nt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n                         wprefetch invpcid_single pti fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms i\n                         nvpcid mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512\n                         bw avx512vl xsaveopt xsavec xgetbv1 xsaves ida arat pku ospke avx512_vnni\nVirtualization features: \n  Hypervisor vendor:     KVM\n  Virtualization type:   full\nCaches (sum of all):     \n  L1d:                   768 KiB (24 instances)\n  L1i:                   768 KiB (24 instances)\n  L2:                    24 MiB (24 instances)\n  L3:                    35.8 MiB (1 instance)\nNUMA:                    \n  NUMA node(s):          1\n  NUMA node0 CPU(s):     0-47\nVulnerabilities:         \n  Gather data sampling:  Unknown: Dependent on hypervisor status\n  Itlb multihit:         KVM: Mitigation: VMX unsupported\n  L1tf:                  Mitigation; PTE Inversion\n  Mds:                   Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unkno\n                         wn\n  Meltdown:              Mitigation; PTI\n  Mmio stale data:       Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unkno\n                         wn\n  Retbleed:              Vulnerable\n  Spec rstack overflow:  Not affected\n  Spec store bypass:     Vulnerable\n  Spectre v1:            Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n  Spectre v2:            Mitigation; Retpolines, STIBP disabled, RSB filling, PBRSB-eIBRS Not affect\n                         ed\n  Srbds:                 Not affected\n  Tsx async abort:       Not affected","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"The following shows the specific GPU information of the g4dn.12xlarge instance used in this project.","category":"page"},{"location":"dev_env_info/","page":"Development Environment Information","title":"Development Environment Information","text":"ubuntu@ip-172-31-4-230:~/trixi_cuda$ nvidia-smi\nSat Dec 30 20:19:54 2023       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       On  | 00000000:00:1B.0 Off |                    0 |\n| N/A   20C    P8               8W /  70W |      2MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       On  | 00000000:00:1C.0 Off |                    0 |\n| N/A   20C    P8              10W /  70W |      2MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   2  Tesla T4                       On  | 00000000:00:1D.0 Off |                    0 |\n| N/A   21C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   3  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n| N/A   20C    P8               9W /  70W |      2MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+","category":"page"},{"location":"#TrixiCUDA.jl","page":"Home","title":"TrixiCUDA.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TrixiCUDA.jl is a component package of the Trixi.jl ecosystem and provides GPU acceleration support for solving hyperbolic partial differential equations (PDEs). ","category":"page"},{"location":"nsys_profiling/#Tutorial-2-Profiling-Kernels-with-Nvidia-Night-Systems","page":"Tutorial 2","title":"Tutorial 2 - Profiling Kernels with Nvidia Night Systems","text":"","category":"section"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Welcome again! This tutorial aims to provide instructions on how to profile CUDA kernels using Nvidia Nsight Systems. The instructions are given based on a cloud Unix system and the VS Code platform (optional).","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Basically, you can accurately measure execution time by:","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"CUDA.@time, a user-friendly measurement tool.\nBenchmarkTools.@benchmark(often used together with CUDA.@sync or CUDA.synchronize()), a robust measurement tool.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"For large applications, simple time measurement is not enough. Here, we introduce Nvidia Nsight Systems for profiling CUDA kernels. This method can provide an overview of how and when the GPU was active, thereby helping identify which kernels need optimization.","category":"page"},{"location":"nsys_profiling/#Create-Profile","page":"Tutorial 2","title":"Create Profile","text":"","category":"section"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Open a new bash terminal and then launch Julia with nsys from Night Systems:","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"$ nsys launch julia","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Enter the package mode and activate the target Julia environment (already configured with the CUDA package):","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"pkg> activate <path-to-your-project>/Project.toml","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Exit the package mode and write your kernels into the Julia command line. Here we use a simple example to show how to profile:","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"julia> using CUDA\njulia> a = CUDA.rand(1024, 1024, 1024)\njulia> sin.(a) # Run it once to force compilation\njulia> CUDA.@profile sin.(a)","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Then a file ending with .nsys-rep (e.g. report1.nsys-rep) will be created in the current directory. This file contains all the profile data.","category":"page"},{"location":"nsys_profiling/#View-Profile","page":"Tutorial 2","title":"View Profile","text":"","category":"section"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Exit the Julia REPL and retrieve data from the .nsys-rep file.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"There are many ways to customize the view of the profile data. Here, we simply mention three methods that can be directly displayed in your terminal.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Display default statistics from a report","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"$ nsys stats report1.nsys-rep","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"This way will export an SQLite file named report1.sqlite from report1.nsys-rep (assuming it does not already exist). Print the default reports in column format to the console.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Display specific data from a report","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"$ nsys stats --report cuda_gpu_trace report1.nsys-rep","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"This way will export an SQLite file named report1.sqlite from report1.nsys-rep (assuming it does not already exist). Print the report generated by the cudagputrace script to the console in column format.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Generate multiple reports, in multiple formats, output multiple places from a report","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"$ nsys stats --report cuda_gpu_trace --report cuda_gpu_kern_sum --report cuda_api_sum --format csv,column --output .,- report1.nsys-rep","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Export an SQLite file named report1.sqlite from report1.nsys-rep (assuming it does not already exist). Generate three reports. The first, the cudagputrace report, will be output to the file report1_cuda_gpu_trace.csv in CSV format. The other two reports, cudagpukernsum and cudaapi_sum, will be output to the console as columns of data.","category":"page"},{"location":"nsys_profiling/#View-Profile-(Optional)","page":"Tutorial 2","title":"View Profile (Optional)","text":"","category":"section"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"This section is for better visualizing the profile report using the VS Code extension. The VS Code platform is required.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"From the previous section, we created .sqlite and .csv files.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"For the .sqlite file, you can download the 'SQLite' extension. Open the Command Palette and enter SQLite: Open Database. Then, you can explore and query the SQLite database from the .sqlite file.","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"For the .csv file, you can download the 'CSV to Table' extension. Open the Command Palette and enter Convert to table from CSV. Then, you can view the CSV file in table format.","category":"page"},{"location":"nsys_profiling/#References","page":"Tutorial 2","title":"References","text":"","category":"section"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"Profiling GPU code in CUDA.jl. https://cuda.juliagpu.org/stable/development/profiling/","category":"page"},{"location":"nsys_profiling/","page":"Tutorial 2","title":"Tutorial 2","text":"NVIDIA Nsight Systems user guide. https://docs.nvidia.com/nsight-systems/UserGuide/index.html","category":"page"}]
}
